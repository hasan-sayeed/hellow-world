{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML-topo",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNYfzkKxLGryZryecnzD4Y3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasan-sayeed/hellow-world/blob/master/ML_topo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcQytuVZJM50"
      },
      "source": [
        "!pip install -q sklearn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlzHBQXsQuWI"
      },
      "source": [
        "tensorflow_version 2.x  # this line is not required unless you are in a notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztCNwc4XQ1Kc"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#for Model\n",
        "import time\n",
        "import sys\n",
        "tooSmall=10\n",
        "\n",
        "#for ModelRun\n",
        "from tensorflow.python.client import timeline\n",
        "import argparse\n",
        "import sys\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "parser = argparse.ArgumentParser()\n",
        "FLAGS = None\n",
        "TYPE=np.float32"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMYzP_7FRX2I"
      },
      "source": [
        "**myInputFn.py**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a1NCfBnQ768"
      },
      "source": [
        "class Scaler:\n",
        "    def __init__(self, d):\n",
        "        self.scaler={}\n",
        "        for key in d.keys():\n",
        "            self.scaler[key] = preprocessing.StandardScaler()\n",
        "            self.scaler[key].fit(d[key].reshape(-1,1))\n",
        "    def __call__(self, x):\n",
        "        X={}\n",
        "        for key in x.keys():\n",
        "            X[key]=self.scaler[key].transform(x[key].reshape(-1,1),copy=True).reshape(-1)\n",
        "        return X\n",
        "    def rescale(self, x): \n",
        "        X={}\n",
        "        for key in x.keys():\n",
        "            X[key]=self.scaler[key].inverse_transform(x[key].reshape(-1,1),copy=True).reshape(-1)\n",
        "        return X\n",
        "    def rescaleAs(self, key, x):\n",
        "        return self.scaler[key].inverse_transform(x.reshape(-1,1),copy=True).reshape(-1)\n",
        "\n",
        "class MyInputFn:\n",
        "    def __init__(self, scaler, x, y=None):\n",
        "        self.scaler=scaler\n",
        "        self.x={}\n",
        "        for key in x.keys():\n",
        "            self.x[key]=np.copy(x[key])\n",
        "        if y is not None:            \n",
        "            self.y={}\n",
        "            for key in y.keys():\n",
        "                self.y[key]=np.copy(y[key])\n",
        "        else:\n",
        "            self.y=y\n",
        "        \n",
        "    def __call__(self, \n",
        "                 num_epochs=1,\n",
        "                 shuffle=False,\n",
        "                 batch_size=128,\n",
        "                 queue_capacity=1000,\n",
        "                 num_threads=1):\n",
        "        x=self.scaler(self.x)\n",
        "        if self.y is None:\n",
        "            y=None\n",
        "        else:\n",
        "            y=self.scaler(self.y)\n",
        "            y=y[y.keys().pop()] # from single y dict to array\n",
        "        return tf.estimator.inputs.numpy_input_fn(x, y, batch_size, num_epochs,shuffle,queue_capacity,num_threads)\n",
        "    \n",
        "    def target(self):        \n",
        "        y=self.y\n",
        "        y=y[y.keys().pop()] # from y dict to array        \n",
        "        return y"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW8JNJ5LRoKp"
      },
      "source": [
        "**model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWAeHDp2RCXN"
      },
      "source": [
        "def createModelFromInput_fn(train_input_fn, hiddenLayers, maxSteps):\n",
        "    featureColumns=tf.contrib.learn.infer_real_valued_columns_from_input_fn(train_input_fn)\n",
        "    optimizer=tf.train.AdamOptimizer()\n",
        "    regressor = tf.contrib.learn.DNNRegressor(feature_columns=featureColumns, hidden_units=hiddenLayers,optimizer=optimizer,activation_fn=tf.nn.tanh)\n",
        "    regressor.fit(input_fn=train_input_fn, max_steps=maxSteps) \n",
        "    return regressor\n",
        "\n",
        "def Score(regressor, input_fn):\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/contrib/learn/MetricSpec\n",
        "    return regressor.evaluate(input_fn=input_fn, steps=1, \n",
        "                           metrics={\n",
        "                               'MSE': tf.contrib.metrics.streaming_mean_squared_error\n",
        "                           })\n",
        "\n",
        "def SelfConsistantCycle(directRegressor, inverseRegressor, scaler, omegaSweep_input_fn_Inverse):    \n",
        "    from myInputFn import MyInputFn\n",
        "    from myInputFn import Scaler\n",
        "    omegaSweep=np.copy(omegaSweep_input_fn_Inverse.x['omega'])\n",
        "    gammaSweep=np.copy(omegaSweep_input_fn_Inverse.x['gamma'])\n",
        "    trendSweep=np.copy(omegaSweep_input_fn_Inverse.x['trend'])\n",
        "    # https://github.com/tensorflow/tensorflow/issues/9505\n",
        "    chiPredicted=scaler.rescaleAs('chi',np.asarray(list(inverseRegressor.predict_scores(input_fn=omegaSweep_input_fn_Inverse(num_epochs=1,shuffle=False))))) # predicted is normalized now rescale\n",
        "    predict_input_fn_Direct = MyInputFn( scaler,\n",
        "        {'chi': chiPredicted, 'gamma': gammaSweep, 'trend': trendSweep})        \n",
        "    omegaPredicted=scaler.rescaleAs('omega',np.asarray(list(directRegressor.predict_scores(input_fn=predict_input_fn_Direct(num_epochs=1,shuffle=False))))) # predicted is normalized now rescale\n",
        "    return chiPredicted,omegaPredicted"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUw3nSaBSEgv"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXpOuEYUSLv9",
        "outputId": "a81f8047-c288-495c-fdf6-07a6e5ebb0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "class Model:\n",
        "    \n",
        "    def __init__(self, dataset, hiddenLayers, maxSteps,model_dir, optimizer, debug):\n",
        "        self.ok=False\n",
        "        if len(dataset['chi'])<tooSmall: # too few points for ml watch out as there will be 10 point just for gamma\n",
        "            return        \n",
        "        self.debug=debug\n",
        "        from myInputFn import Scaler\n",
        "        # scaler\n",
        "        self.scaler=Scaler(dataset) \n",
        "        # split\n",
        "        from sklearn import model_selection\n",
        "        featKeys=[]\n",
        "        featTest=[]\n",
        "        featTrain=[]\n",
        "        if debug:\n",
        "            rnd=4852\n",
        "        else:\n",
        "            rnd=np.random.randint((2**31)*2)\n",
        "        \n",
        "        for key, val in dataset.iteritems():\n",
        "            train,test= model_selection.train_test_split(val, test_size=0.2 , random_state=rnd)\n",
        "            if key=='chi' or key=='omega':\n",
        "                if key=='omega':\n",
        "                    omegaTrain=train\n",
        "                    omegaTest=test\n",
        "                else:\n",
        "                    chiTrain=train\n",
        "                    chiTest=test\n",
        "            else:                \n",
        "                featKeys.append(key)\n",
        "                featTest.append(test)\n",
        "                featTrain.append(train)\n",
        "    \n",
        "        from myInputFn import MyInputFn\n",
        "        \n",
        "        \n",
        "        # Direct regressor\n",
        "        directTrainFeatures={'chi': chiTrain}\n",
        "        for i,key in enumerate(featKeys):\n",
        "            directTrainFeatures[key]=featTrain[i]\n",
        "            \n",
        "        train_input_fn_Direct = MyInputFn( self.scaler,\n",
        "            directTrainFeatures,\n",
        "            {'omega':omegaTrain})\n",
        "        \n",
        "        startTime = time.time()    \n",
        "        self.directRegressor = self.createModelFromInput_fn(train_input_fn_Direct(num_epochs=None,shuffle=True), hiddenLayers, maxSteps,model_dir+\"/direct\", optimizer)\n",
        "        print('# Direct Fitting time: %f' % (time.time() - startTime))\n",
        "\n",
        "        # test direct regressor\n",
        "        directTestFeatures={'chi': chiTest}\n",
        "        for i,key in enumerate(featKeys):\n",
        "            directTestFeatures[key]=featTest[i]\n",
        "        \n",
        "        test_input_fn_Direct = MyInputFn( self.scaler,\n",
        "            directTestFeatures,\n",
        "            {'omega':omegaTest})\n",
        "\n",
        "        from model import Score        \n",
        "        self.scoreDirect=self.Score(self.directRegressor,test_input_fn_Direct(num_epochs=1,shuffle=False))\n",
        "        print'# Direct MSE: '+str(self.scoreDirect['MSE'])\n",
        "\n",
        "        # Inverse regressor\n",
        "        invTrainFeatures={'omega': omegaTrain}\n",
        "        for i,key in enumerate(featKeys):\n",
        "            invTrainFeatures[key]=featTrain[i]\n",
        "        \n",
        "        train_input_fn_Inverse = MyInputFn( self.scaler,\n",
        "            invTrainFeatures,\n",
        "            {'chi':chiTrain})\n",
        "        startTime = time.time()    \n",
        "        self.inverseRegressor = self.createModelFromInput_fn(train_input_fn_Inverse(num_epochs=None,shuffle=True), hiddenLayers, maxSteps,model_dir+\"/inverse\", optimizer)\n",
        "        print('# Inverse Fitting time: %f' % (time.time() - startTime))\n",
        "\n",
        "        invTestFeatures={'omega': omegaTest}\n",
        "        for i,key in enumerate(featKeys):\n",
        "            invTestFeatures[key]=featTest[i]\n",
        "        \n",
        "        test_input_fn_Inverse = MyInputFn( self.scaler,\n",
        "            invTestFeatures,\n",
        "            {'chi':chiTest})        \n",
        "        self.scoreInverse=self.Score(self.inverseRegressor,test_input_fn_Inverse(num_epochs=1,shuffle=False))\n",
        "        print'# Inverse MSE: '+str(self.scoreInverse['MSE'])    \n",
        "        \n",
        "        # calc omega range BUG BUG 1 d lin\n",
        "        if dataset.has_key('gamma'):\n",
        "            self.OmegaMinGamma(dataset['omega'], dataset['gamma'])\n",
        "        self.isChiPositive=np.min(dataset['chi'])>0.0\n",
        "        self.ok=True\n",
        "\n",
        "    def createModelFromInput_fn(self, train_input_fn, hiddenLayers, maxSteps, model_dir, optimizer):\n",
        "        if self.debug:\n",
        "            rnd=87897978\n",
        "            cores=1\n",
        "        else:\n",
        "            rnd=None\n",
        "            cores=0            \n",
        "        my_checkpointing_config = tf.estimator.RunConfig(\n",
        "            save_checkpoints_steps=maxSteps/10,\n",
        "            keep_checkpoint_max = 10,       # Retain the 10 most recent checkpoints.\n",
        "            tf_random_seed=rnd,\n",
        "            # num_cores= cores\n",
        "        )\n",
        "                \n",
        "        if(optimizer=='grad'):\n",
        "            opt=tf.train.GradientDescentOptimizer(0.001)\n",
        "        elif(optimizer=='prox'):\n",
        "            opt=tf.train.ProximalGradientDescentOptimizer(0.001)\n",
        "        else:\n",
        "            opt=tf.train.AdamOptimizer()\n",
        "        featureColumns=tf.contrib.learn.infer_real_valued_columns_from_input_fn(train_input_fn)\n",
        "        regressor = tf.contrib.learn.DNNRegressor(feature_columns=featureColumns, hidden_units=hiddenLayers,optimizer=opt,activation_fn=tf.nn.tanh, model_dir=model_dir,config=my_checkpointing_config)\n",
        "        regressor.fit(input_fn=train_input_fn, max_steps=maxSteps) \n",
        "        return regressor\n",
        "    \n",
        "    def Score(self, regressor, input_fn):\n",
        "        # https://www.tensorflow.org/api_docs/python/tf/contrib/learn/MetricSpec\n",
        "        return regressor.evaluate(input_fn=input_fn, steps=1, \n",
        "                               metrics={\n",
        "                                   'MSE': tf.contrib.metrics.streaming_mean_squared_error\n",
        "                               })\n",
        "    def OmegaMinGamma(self, omega, gamma):\n",
        "        u,v=np.unique(gamma, True)\n",
        "        gammaVal=[]\n",
        "        omegaMin=[]\n",
        "        omegaMax=[]\n",
        "        s=None\n",
        "        for x in v: # select each gamma group\n",
        "            if s is not None: # find offsets of gamma groups\n",
        "                gammaVal.append(gamma[s])\n",
        "                omegaMin.append(np.min(omega[s:x]))\n",
        "                omegaMax.append(np.max(omega[s:x]))\n",
        "            s=x\n",
        "        gammaVal.append(gamma[s])\n",
        "        omegaMin.append(np.min(omega[s:]))\n",
        "        omegaMax.append(np.max(omega[s:]))\n",
        "        # regression\n",
        "        if len(gammaVal)<2:\n",
        "            self.slopeOmn, self.interceptOmn = 0.0,np.min(omega)\n",
        "            self.slopeOmx, self.interceptOmx=0.0,np.max(omega)\n",
        "        else:\n",
        "            from scipy import stats\n",
        "            self.slopeOmn, self.interceptOmn, r_value, p_value, std_err =stats.linregress(gammaVal,omegaMin)\n",
        "            self.slopeOmx, self.interceptOmx, r_value, p_value, std_err =stats.linregress(gammaVal,omegaMax)\n",
        "        return {'gamma':np.array(gammaVal).reshape(-1), 'omegaMin':np.array(omegaMin).reshape(-1), 'omegaMax':np.array(omegaMax).reshape(-1)}\n",
        "    \n",
        "    def omegaRange(self, gamma):\n",
        "        omn=self.slopeOmn*gamma+ self.interceptOmn\n",
        "        omx=self.slopeOmx*gamma+ self.interceptOmx\n",
        "        return omn, omx\n",
        "    \n",
        "    def SelfConsistantCycle(self, omegaSweep_input_fn_Inverse):    \n",
        "        from myInputFn import MyInputFn\n",
        "        from myInputFn import Scaler\n",
        "        import math\n",
        "        chiPredicted=self.scaler.rescaleAs('chi',np.asarray(list(self.inverseRegressor.predict_scores(input_fn=omegaSweep_input_fn_Inverse(num_epochs=1,shuffle=False))))) # predicted is normalized now rescale\n",
        "        chiUpperBoundIdx=np.abs(chiPredicted)<math.pi # keep only valid chi and correct \n",
        "        if self.isChiPositive:\n",
        "            chiLowerBoundIdx=chiPredicted>0.0 \n",
        "        else:\n",
        "            chiLowerBoundIdx=chiPredicted<0.0 \n",
        "        validChiIdx=np.logical_and(chiLowerBoundIdx,chiUpperBoundIdx)   \n",
        "        chiPredicted=chiPredicted[validChiIdx]\n",
        "        if(np.count_nonzero(chiPredicted)<2): # too few points\n",
        "            return None,None, None \n",
        "        features={}\n",
        "\n",
        "        for key in omegaSweep_input_fn_Inverse.x.keys():\n",
        "            if key != 'omega':\n",
        "                features[key]=np.copy(omegaSweep_input_fn_Inverse.x[key])[validChiIdx]\n",
        "            else:\n",
        "                deviation=np.copy(omegaSweep_input_fn_Inverse.x[key])[validChiIdx] # original omegas\n",
        "        # should it return here?        \n",
        "        features['chi']=chiPredicted\n",
        "        predict_input_fn_Direct = MyInputFn( self.scaler, features)        \n",
        "        omegaPredicted=self.scaler.rescaleAs('omega',np.asarray(list(self.directRegressor.predict_scores(input_fn=predict_input_fn_Direct(num_epochs=1,shuffle=False))))) # predicted is normalized now rescale\n",
        "        deviation=omegaPredicted[:]-deviation[:]\n",
        "        return chiPredicted,omegaPredicted, deviation\n",
        "\n",
        "def padding(x):\n",
        "        mid=len(x)/2\n",
        "        X=np.append(-x[mid:0:-1]+2*x[0],x) \n",
        "        X=np.append(X,-x[-2:mid:-1]+2*x[-1])\n",
        "        return X\n",
        "\n",
        "def extendSymetrically(dataset,targetKey):\n",
        "    for i,key in enumerate(dataset):\n",
        "        if(key!=targetKey):\n",
        "            mid=len(dataset[key])/2\n",
        "            # rightmost half\n",
        "            # y0=dataset[targetKey][-1]\n",
        "            extend=dataset[key][:mid-1:-1]            \n",
        "            x0=extend[0]\n",
        "            extend=x0-(extend-x0)\n",
        "            extendY=dataset[target][:mid-1:-1]\n",
        "            y0=extendY[0]\n",
        "            extendY=y0-(extendY-y0)\n",
        "            # BUG BUG multi D ??\n",
        "            \n",
        "    return\n",
        "def test():\n",
        "    def omega(x):\n",
        "        return 1.0+x*x+x*x*x\n",
        "    def dOmega(x):\n",
        "        return x*(2+3*x)\n",
        "    def trend(x):\n",
        "        return np.sign(dOmega(x))\n",
        "    def es():\n",
        "        chi=np.linspace(-0.5,1.5,20, dtype=np.float32)\n",
        "        ds={'chi':chi, 'omega':omega(chi)}\n",
        "        extendSymetrically(ds,'omega')\n",
        "        \n",
        "    es()\n",
        "    import matplotlib.pyplot as plt\n",
        "    hiddenLayers=[122,122,122,122]\n",
        "    maxSteps=1500\n",
        "    model_dir='/tmp/test-model/'\n",
        "    chi=np.linspace(-0.5,1.5,20, dtype=np.float32)    \n",
        "    om=omega(chi)\n",
        "\n",
        "    plt.show()\n",
        "    datasetS={'chi':chi,'omega':om}\n",
        "    modelS=Model(datasetS, hiddenLayers, maxSteps,model_dir+'S/')\n",
        "    # extend by reflection\n",
        "    X0=chi[-1]\n",
        "    ihc=chi[::-1]-X0\n",
        "    ihc=-ihc+X0\n",
        "    ihc=np.append(chi,ihc)\n",
        "    \n",
        "    Y0=om[-1]\n",
        "    mo=om[::-1]-Y0\n",
        "    mo=-mo+Y0\n",
        "    mo=np.append(om,mo)\n",
        "    \n",
        "    datasetR={'chi':ihc,'omega':mo}    \n",
        "    modelR=Model(datasetR, hiddenLayers, maxSteps,model_dir+'R/')\n",
        "    from myInputFn import MyInputFn\n",
        "    input_fn_S = MyInputFn(modelS.scaler,\n",
        "            {'chi': np.linspace(-0.5,1.5,200, dtype=np.float32)})                                \n",
        "    predictS=modelS.scaler.rescaleAs('omega',np.asarray(list(modelS.directRegressor.predict_scores(input_fn=input_fn_S(num_epochs=1,shuffle=False))))) # predicted is normalized now rescale\n",
        "    input_fn_R = MyInputFn(modelR.scaler,\n",
        "                           {'chi': np.linspace(-0.5,1.5,200, dtype=np.float32)})                                    \n",
        "    predictR=modelR.scaler.rescaleAs('omega',np.asarray(list(modelR.directRegressor.predict_scores(input_fn=input_fn_R(num_epochs=1,shuffle=False))))) # predicted is normalized now rescale\n",
        "\n",
        "    plt.plot(input_fn_R.x['chi'],predictR, 'r+')\n",
        "    plt.plot(input_fn_S.x['chi'],predictS, 'b+')\n",
        "    plt.plot(chi, om, 'bo')\n",
        "    plt.plot(ihc, mo, 'g-')\n",
        "    # plt.plot(ihc, mo, 'g+')\n",
        "    plt.show()\n",
        "    \n",
        "# test()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-492c4914409a>\"\u001b[0;36m, line \u001b[0;32m62\u001b[0m\n\u001b[0;31m    print'# Direct MSE: '+str(self.scoreDirect['MSE'])\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkE2p-AcShv_"
      },
      "source": [
        "**ModelRun**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IFXpSepSghS",
        "outputId": "4ce27feb-595d-4c7b-e590-689ce1b4ba13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "def main(_):\n",
        "    from Model import padding\n",
        "    # mode from 1 ... ncol-1 , trend next col NEW last col gamma\n",
        "    def readData(fileName):\n",
        "        def mkarray(x):\n",
        "            return np.array([x],dtype=TYPE)\n",
        "        infile=open(fileName) if len(fileName) else sys.stdin \n",
        "        dataRaw=np.array([ np.array([mkarray(token) for token in line.split()]) for line in infile.readlines()])\n",
        "        chi=dataRaw[:, 0, None].reshape(-1) \n",
        "        indexes=chi>0.0\n",
        "        datasetPositiveChi=dataRaw[indexes,:]\n",
        "        indexes=chi<0.0\n",
        "        datasetNegativeChi=dataRaw[indexes,:]\n",
        "        \n",
        "        return datasetPositiveChi,datasetNegativeChi\n",
        "    class SelectMode:\n",
        "        def __init__(self,padding):\n",
        "            self.padding=padding\n",
        "        def __call__(self,data, mode, trendSelected):    \n",
        "            ds=self._selectMode(data, mode, trendSelected)\n",
        "            if not self.padding:\n",
        "                return ds\n",
        "            \n",
        "            gamma=ds['gamma']\n",
        "            u,idx=np.unique(gamma, True) # values and indexes returned\n",
        "            s=None\n",
        "            chiOriginal=ds['chi']\n",
        "            omegaOriginal=ds['omega']\n",
        "            chiPadded=[]\n",
        "            omegaPadded=[]\n",
        "            gammaPadded=[] # this is not really padded just corrected for size\n",
        "            for x in idx:\n",
        "                if s is not None:\n",
        "                    chi=chiOriginal[s:x]\n",
        "                    chi=padding(chi)\n",
        "                    gm=np.zeros_like(chi)\n",
        "                    gm[:]=gamma[s] # enlarge gamma and fill with correct value\n",
        "                    gammaPadded.append(gm)\n",
        "                    chiPadded.append(chi)\n",
        "                    omega=omegaOriginal[s:x]\n",
        "                    omegaPadded.append(padding(omega))\n",
        "                s=x\n",
        "            # repeat one last time\n",
        "            chi=chiOriginal[s:]\n",
        "            chi=padding(chi)\n",
        "            gm=np.zeros_like(chi)\n",
        "            gm[:]=gamma[s] \n",
        "            gammaPadded.append(gm)\n",
        "            chiPadded.append(chi)\n",
        "            omega=omegaOriginal[s:]\n",
        "            omegaPadded.append(padding(omega))\n",
        "            gammaPadded=np.array(gammaPadded)\n",
        "            gammaPadded=gammaPadded.reshape(-1)            \n",
        "            chiPadded=np.array(chiPadded)\n",
        "            chiPadded=chiPadded.reshape(-1)\n",
        "            omegaPadded=np.array(omegaPadded)\n",
        "            omegaPadded=omegaPadded.reshape(-1)\n",
        "            fp=open('padded.chi.dat','ab')\n",
        "            np.savetxt(fp,chiPadded)\n",
        "            fp.close()\n",
        "            fp=open('padded.om.dat','ab')\n",
        "            np.savetxt(fp,omegaPadded)\n",
        "            fp.close()\n",
        "            print 'saved'\n",
        "            chiPadded=np.array(chiPadded).reshape(-1)\n",
        "            omegaPadded=np.array(omegaPadded).reshape(-1)\n",
        "            gammaPadded=np.array(gammaPadded).reshape(-1)\n",
        "            return {'chi':chiPadded,'omega':omegaPadded,'gamma':gammaPadded}\n",
        "        \n",
        "        \n",
        "        def _selectMode(self,data, mode, trendSelected):    \n",
        "            modeCol=1+(mode-1)*2\n",
        "            # indexes=[len(rec)>(modeCol+1) for rec in dataRaw]\n",
        "            # data=dataRaw[indexes]\n",
        "            chi=data[:, 0, None] \n",
        "            omega=data[:, modeCol ,None] \n",
        "            gamma=data[:, -1, None] # last column is gamma\n",
        "            trend=data[:, (modeCol+1) ,None] # slope field follows omega field\n",
        "            trend=np.sign(trend)\n",
        "            indexes=trend==trendSelected\n",
        "            return {'chi':chi[indexes],'omega':omega[indexes], 'gamma':gamma[indexes]}        \n",
        "        \n",
        "    # prepare from flags\n",
        "    hiddenLayers= eval('['+FLAGS.hiddenLayers+']')\n",
        "    model_dir=FLAGS.export+'/'+FLAGS.hiddenLayers.replace(',','-')+'/'\n",
        "    maxSteps = eval('int('+FLAGS.maxSteps+')')\n",
        "    omegaStep=eval('float('+FLAGS.omegaStep+')')\n",
        "    outfile=sys.stdout if FLAGS.output=='' else open(FLAGS.output,'w')\n",
        "    outfile.write('# data: '+ FLAGS.data +\"\\n\")\n",
        "    outfile.write('# hiddenLayers: ['+ FLAGS.hiddenLayers+']' +\"\\n\")\n",
        "    outfile.write('# maxSteps: '+ FLAGS.maxSteps +\"\\n\")\n",
        "    outfile.write('# optimizer: '+ FLAGS.opt +\"\\n\")\n",
        "    run_metadata=tf.RunMetadata()\n",
        "    def comment(): # not working\n",
        "        trace = timeline.Timeline(step_stats=run_metadata.step_stats)\n",
        "        # chrome://tracing\n",
        "        # https://github.com/tensorflow/tensorflow/issues/1824#issuecomment-225754659\n",
        "        # https://www.tensorflow.org/performance/performance_guide\n",
        "        import os\n",
        "        try:\n",
        "            os.stat(model_dir)\n",
        "        except:\n",
        "            os.mkdir(model_dir)   \n",
        "        trace_file = open(model_dir+'timeline.ctf.json', 'w')\n",
        "    debug= True if FLAGS.debug else False\n",
        "    if debug:\n",
        "        os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
        "        \n",
        "    optimizer=FLAGS.opt\n",
        "    if(FLAGS.opt=='grad'):\n",
        "        model_dir=model_dir+'grad/'\n",
        "    elif(FLAGS.opt=='prox'):\n",
        "        model_dir=model_dir+'prox/'\n",
        "    else:\n",
        "        model_dir=model_dir # +'adam/'\n",
        "        \n",
        "    datasetPositiveChi,datasetNegativeChi=readData(FLAGS.data)\n",
        "    padded=True if FLAGS.pad else False\n",
        "    selectMode=SelectMode(padded)\n",
        "    from Model import Model\n",
        "    model={}\n",
        "    modeRange= eval('range('+FLAGS.modeRange+')' ) if ',' in FLAGS.modeRange else [int(FLAGS.modeRange)]  # else single mode value    \n",
        "    # create seperate models for each mode & trend with extra gamma feature \n",
        "    \n",
        "    for mode in modeRange:\n",
        "        for trend in range(-1,2,2):\n",
        "            nm='p_'+str(mode)+'_'+str(trend)\n",
        "            m=Model(selectMode(datasetPositiveChi, mode, trend), hiddenLayers, maxSteps, model_dir+nm, optimizer, debug) # positive only\n",
        "            # trace_file.write(trace.generate_chrome_trace_format())\n",
        "            if m.ok :\n",
        "                model[nm]=m\n",
        "            nm='n_'+str(mode)+'_'+str(trend)\n",
        "            m=Model(selectMode(datasetNegativeChi, mode, trend), hiddenLayers, maxSteps, model_dir+nm, optimizer, debug)\n",
        "            \n",
        "            if m.ok :\n",
        "                model[nm]=m\n",
        "    # run models one for each mode & trend with extra gamma feature     \n",
        "    \n",
        "    from myInputFn import MyInputFn\n",
        "    gammaValues= eval('np.linspace('+FLAGS.gammaRange+', dtype=TYPE)' ) if ',' in FLAGS.gammaRange else [TYPE(FLAGS.gammaRange)]  # else single gamma value    \n",
        "    omegaTarget= eval('np.linspace('+FLAGS.omegaRange+', dtype=TYPE)' ) if ',' in FLAGS.omegaRange else None  # else auto \n",
        "    if omegaTarget is not None:\n",
        "        outfile.write('# omegaRange: '+ FLAGS.omegaRange +\"\\n\")\n",
        "    trendFilter =False if FLAGS.trendFilter_off else True\n",
        "    if trendFilter:\n",
        "        outfile.write('# trendFilter ON' +\"\\n\")\n",
        "    \n",
        "    for mode in modeRange:\n",
        "        for trend in range(-1,2,2):\n",
        "            for s in ['p','n']:\n",
        "                nm=s+'_'+str(mode)+'_'+str(trend)\n",
        "                if nm in model:\n",
        "                    for gammaValue in gammaValues:\n",
        "                        if omegaTarget is None:\n",
        "                            omegaMin,omegaMax=model[nm].omegaRange(gammaValue)  \n",
        "                            omegaPts=abs(int((omegaMin-omegaMax)/omegaStep))\n",
        "                            omegaSweep=np.linspace(omegaMin,omegaMax, omegaPts)\n",
        "                        else:\n",
        "                            omegaSweep=np.copy(omegaTarget)\n",
        "                        # LP cleanup - do a small step in omega to test trend\n",
        "                        if trendFilter:\n",
        "                            deltaOmega=np.abs(omegaSweep[1]-omegaSweep[0])*1e-3\n",
        "                            tmp=np.append(omegaSweep, omegaSweep)\n",
        "                            tmp[::2]=omegaSweep[:]\n",
        "                            tmp[1::2]=omegaSweep[:]+deltaOmega\n",
        "                            omegaSweep=tmp\n",
        "                        print \"# model: \"+nm+\" gammaValue: \"+str(gammaValue)\n",
        "                        gammaSweep=np.zeros_like(omegaSweep)\n",
        "                        gammaSweep[:]=gammaValue\n",
        "                        omegaSweep_input_fn_Inverse = MyInputFn(model[nm].scaler, # not great\n",
        "                            {'omega': omegaSweep, 'gamma': gammaSweep})                                \n",
        "                        chiPredicted,omegaPredicted,deviation=model[nm].SelfConsistantCycle(omegaSweep_input_fn_Inverse) # still need to do lp clean up \n",
        "                        if chiPredicted is not None:\n",
        "                            if trendFilter:\n",
        "                                trendPredicted=np.zeros_like(chiPredicted)\n",
        "                                trendPredicted[:-1]=(omegaPredicted[1:]-omegaPredicted[:-1])/(chiPredicted[1:]-chiPredicted[:-1])\n",
        "                                trendPredicted[-1]=trendPredicted[-2] # assume trend on last\n",
        "                                trendPredicted=np.sign(trendPredicted)\n",
        "                                goodTrendIdx= trendPredicted==trend\n",
        "                                goodTrendIdx[1::2]=False # eliminate all deltaOmega\n",
        "                            else:\n",
        "                                goodTrendIdx=range(len(chiPredicted))\n",
        "                            outfile.write(\"# \"+nm+\": omegaSC\\tdeviation\\tchi\\tgamma\\ttrend\\tmode\\n\")\n",
        "                            output(outfile,omegaPredicted[goodTrendIdx], deviation[goodTrendIdx], chiPredicted[goodTrendIdx], gammaValue, trend, mode)\n",
        "                \n",
        "def output(outfile, omegaSC, deviation,chi,gamma,trend, mode):\n",
        "\n",
        "    for i in range(len(omegaSC)):\n",
        "        outfile.write(str(omegaSC[i])+\"\\t\"+str(deviation[i])+\"\\t\"+str(chi[i])+\"\\t\"+str(gamma)+\"\\t\"+str(trend)+\"\\t\"+str(mode)+\"\\n\")\n",
        "    outfile.write(\"\\n\\n\")\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "    parser.add_argument('--maxSteps', type=str, default='25000',\n",
        "                        help='maxSteps [25000] int ')   \n",
        "\n",
        "    parser.add_argument('--omegaStep', type=str, default='0.00002',\n",
        "                        help='omegaStep [0.00002] float ')   \n",
        "\n",
        "    \n",
        "    parser.add_argument('--hiddenLayers', type=str, default='131,131,131,131,131',\n",
        "                        help='hiddenLayers [131,131,131,131,131] e.g. 12,12,12,12 as in list')   \n",
        "        \n",
        "    parser.add_argument('--data', type=str, default='',\n",
        "                      help='Input file [stdin]')\n",
        "\n",
        "    parser.add_argument('--export', type=str, default='/tmp/model',\n",
        "                        help='Export model to path [/tmp/model]')\n",
        "    \n",
        "    parser.add_argument('--gammaRange', type=str, default='0.10,0.20,11',\n",
        "                        help='gamma range [0.10,0.20,11] e.g. 10,12,300 as in np.linspace')   \n",
        "    \n",
        "    parser.add_argument('--modeRange', type=str, default='1,7',\n",
        "                        help='mode index range [1,7] e.g. 1,2 as in range')   \n",
        "    \n",
        "    parser.add_argument('--omegaRange', type=str, default='',\n",
        "                        help='omega range [auto] e.g. 5.67,5.7,100 as in linspace ')   \n",
        "    \n",
        "    parser.add_argument('--output', type=str, default='',\n",
        "                        help='filename [stdout]')   \n",
        "    \n",
        "    parser.add_argument('--opt', type=str, default='',\n",
        "                        help='optimizer [adam] e.g. grad | prox ')   \n",
        "\n",
        "    parser.add_argument('--pad', action='store_true',\n",
        "                        help='extend by padding')   \n",
        "    \n",
        "    parser.add_argument('--debug', action='store_true',\n",
        "                        help='Fixed random seed and one CPU no GPU')   \n",
        "    \n",
        "    parser.add_argument('--trendFilter-off', action='store_true',\n",
        "                        help='Trend filter off')   \n",
        "    \n",
        "    FLAGS, unparsed = parser.parse_known_args()\n",
        "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-a1d2dc45afac>\"\u001b[0;36m, line \u001b[0;32m64\u001b[0m\n\u001b[0;31m    print 'saved'\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print('saved')?\n"
          ]
        }
      ]
    }
  ]
}